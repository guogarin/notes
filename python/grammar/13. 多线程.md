## 1. 并发和并行
Effective Python 第七章的前言总结的很好。






&emsp;
&emsp; 
# 2. GIL锁
## 2.1 什么是GIL锁？
&emsp;&emsp; `GIL`全称`Global Interpreter Lock`(全局解释器锁)，缩写GIL）,是计算机程序设计语言解释器 **用于同步线程** 的一种机制，它使得任何时刻仅有一个线程在执行。
&emsp;&emsp; 简单来说，GIL 是一个互斥锁，它规定解释器同一时刻只允许一个线程运行。

&emsp;
## 2.2 GIL锁 是Python带来的吗？
&emsp;&emsp; 首先需要明确的一点是`GIL`并不是Python的特性，它是**在实现Python解析器(CPython)时**所引入的一个概念。
&emsp;&emsp; 我们知道python有`CPython`，`PyPy`和`JPython`。像其中的`JPython`就没有`GIL`。然而因为`CPython`是大部分环境下默认的Python执行环境。所以在很多人的概念里`CPython`就是Python，也就想当然的把`GIL`归结为Python语言的缺陷。所以这里要先明确一点：`GIL`并不是Python的特性，Python完全可以不依赖于`GIL`。

&emsp;
## 2.3 为什么需要GIL？
### 2.3.1 GIL 为Python解决了什么问题？
&emsp;&emsp; 我们知道，Python的内存管理是通过引用计数(reference counting)来完成的。当某对象的引用计数变量的值为 0 时，会将这个对象在内存中占用的资源释放。下面通过一个例子来看看引用计数如何工作：
```python
import sys

a = []
b = a 
print(sys.getrefcount(a))
```
运行结果：
```
3
```
**结果分析：**
&emsp;&emsp; 这`3`个分别是：`a`, `b`, `sys.getrefcount()`
问题是在多个线程试图修改这个 引用计数变量 时会引发竞态条件：
> &emsp;&emsp; 假设有两个线程A和B，它们共享了一个dict对象，在同一时刻，线程A增加了这个dict的引用计数，而线程B减少了这个dict的引用计数，此时就引发了竟态条件，这个dict的引用计数的值很可能就不准确了，这可能造成 内存泄漏 或 内存被提前释放，或者其它莫名其妙的bug。
> 
因此，为防止上述竟态条件的发生，必须给它加锁。

### 2.3.2 为什么选择 全局锁？而不是给每个对象的引用计数单独枷锁？
&emsp;&emsp; 如果我们给每个创建的对象都加上一把锁，那么很可能会出现一个问题 —— 死锁。
&emsp;&emsp; 另外，给每个对象的引用计数都加锁的话，会因为频繁的获取/释放锁而降低程序的性能。
因此，不能给每个对象的引用计数单独枷锁，只能用全局锁。

### 2.3.3 其它原因
&emsp;&emsp; 在 Python 刚诞生那会儿，操作系统甚至还没有线程这个概念。Python 的设计初衷：易学易用，加快开发者们工作的进度。
&emsp;&emsp; 另外GIL 比较容易实现，添加到 Python 中也很方便。因为只需要管理一个锁，提高了单线程程序的性能。

### 2.3.4 总结
&emsp;&emsp; Python的内存管理是通过引用计数来完成的，但问题是这个引用计数并不是线程安全的，多个线程在修改引用计数时可能会引发的竟态条件，所以必须加锁，此时我们有两种方案：
> ① 给每个对象的引用计数单独枷锁
> ② 加一个全局锁
> 
但问题是给每个对象的引用计数单独枷锁会导致死锁，而且频繁的加解锁也会降低程序性能，所以只能加一个全局锁(即GIL)来保护 引用计数。

&emsp;
## 2.4 GIL 是如何运作的？
TODO:

&emsp;
## 2.5 为什么不在 Python 3 中删除它？
**(1) 去掉GIL会降低单线程性能**
&emsp;&emsp; Python3 确实有机会从头开始，包括重写现存的一些 C 扩展。但 GIL并不是一无是处，它的存在使python的单线程的性能非常强大，曾经有人实现过不带GIL的解释器，但代价却是单线程性能却下降了好几倍。
**(2) 对于那些必须高效利用CPU核心的应用，可以寻求其它替代方案**
&emsp;&emsp; 对于IO密集型引用，GIL影响很小；而对于CPU密集型应用，可以使用其它替代方案(如多进程)。

&emsp;
## 2.6 GIL锁的影响
### 2.6.1 GIL会带来什么影响？
&emsp; GIL主要会影响多线程程序：
> &emsp;&emsp; 尽管Python完全支持多线程编程，但是解释器的C语言实现部分在完全并行执行时并不是线程安全的。 实际上，解释器被一个全局解释器锁保护着，它确保任何时候都只有一个Python线程执行。
> 
带来的问题是：
> &emsp;&emsp; Python的多线程程序并不能利用多核CPU的优势，对于一个使用了多个线程的程序，同一时间只能有一个线程被执行，即使其它几个CPU都是空闲状态。
> 

### 2.6.2 多线程编程中，如何最大程度的避免GIL锁带来的影响？
&emsp; 我们都知道，程序大概可以分成两类
> &emsp;&emsp; ① IO密集型
> &emsp;&emsp; ② CPU密集型
> 
对于**IO密集型**的多线程程序，`GIL` 对 的很友好，可以大大提高其性能。因为它们大部分时间都在等待，当一个线程等待 I/O 的时候，GIL让前者睡眠，然后启动另外的线程。
而对于**CPU密集型**的多线程程序，如果GIL 的存在给程序性能造成了影响，可以尝试一下的解决方案：
> &emsp;&emsp; ① 使用多进程；
> &emsp;&emsp; ② 换个解释器

&emsp;
## 2.7 GIL是否意味着线程安全？
&emsp;&emsp; 不是

## 2.8 GIL锁的存在是否意味着python多线程一点用也没有了？
&emsp;&emsp; 不是，GIL只对CPU密集型应用影响比较大，IO密集型应用影响有限。

&emsp;
## 参考文献
1. [翻译：什么是全局解释器锁GIL？](https://zhuanlan.zhihu.com/p/67349209)
2. [What Is the Python Global Interpreter Lock (GIL)?](https://realpython.com/python-gil/)
3. [CPython有GIL是因为当年设计CPython的人偷懒吗？](https://www.zhihu.com/question/439920631/answer/1685766305)
4. [为什么 Python的GIL问题一直让人诟病，Python社区却不解决？](https://www.zhihu.com/question/323812020/answer/2219586213)
5. [面试官：你如何破解 Python的 GIL 的？这才是完美的回答](https://zhuanlan.zhihu.com/p/407236410)
6. [深入理解Python中的GIL](https://zhuanlan.zhihu.com/p/75780308)
7. [python cookbook]()
8. [python的GIL锁](https://blog.csdn.net/qq_43517875/article/details/109131380)







&emsp;
&emsp; 
# 3. 协程(Coroutines)
## 16.2 用作协程的生成器的基本行为
```python
def simple_coroutine(): # ➊
    print('-> coroutine started')
    x = yield # ➋
    print('-> coroutine received:', x)

my_coro = simple_coroutine()
print(my_coro )
next(my_coro)
my_coro.send(42) 
```

下面的代码在命令行运行：
```python
>>> from inspect import getgeneratorstate
>>> 
>>>
>>> def simple_coro2(a):
...     print('-> Started: a =', a)
...     b = yield a
...     print('-> Received: b =', b)
...     c = yield a + b
...     print('-> Received: c =', c)
...
>>>
>>> my_coro2 = simple_coro2(14)
>>>
>>> print(getgeneratorstate(my_coro2) )
GEN_CREATED

>>> next(my_coro2)
-> Started: a = 14
14

>>> print(getgeneratorstate(my_coro2) )
GEN_SUSPENDED

>>> my_coro2.send(28)
-> Received: b = 28
42

>>> my_coro2.send(99)
-> Received: c = 99
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
StopIteration

>>> print(getgeneratorstate(my_coro2) )
GEN_CLOSED
```


# 预激协程(Coroutine Priming)
&emsp;&emsp; 如果不预激，那么协程没什么用。调用 `my_coro.send(x)` 之前，记住一定要调用 `next(my_coro)`。
## 用装饰器来预激协程
为了简化协程的用法，有时会使用一个预激装饰器，比如：
```python
from functools import wraps


def coroutine(func):
    """Decorator: primes `func` by advancing to first `yield`"""
    @wraps(func)
    def primer(*args,**kwargs):
        gen = func(*args,**kwargs)
        next(gen)  #  预激生成器
        return gen # 返回预激的生成器
    return primer


@coroutine # ➎
def averager(): # ➏
    total = 0.0
    count = 0
    average = None
    while True:
        term = yield average
        total += term
        count += 1
        average = total/count
```
在命令行运行一下上面的代码：
```python
'''
    关于 @coroutine装饰器 和 averager()的定义省略...
'''

>>> coro_avg = averager()

>>> coro_avg.send(40) # ➊
40.0

>>> coro_avg.send(50)
45.0

>>> coro_avg.send('spam') # ➋  
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 8, in averager
TypeError: unsupported operand type(s) for +=: 'float' and 'str'

>>> coro_avg.send(60) # ➌
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
StopIteration
```
> ❶ 调用 `averager()` 函数创建一个生成器对象， 在 `coroutine` 装饰器的 `primer` 函数中已经预激了这个生成器。
> ❷ `getgeneratorstate` 函数指明， 处于 `GEN_SUSPENDED` 状态， 因此这个协程已经准备好， 可以接收值了。
> ❸ 可以立即开始把值发给 `coro_avg`——这正是 `coroutine` 装饰器的目的。
> 

## 终止协程和异常处理(Coroutine Termination and Exception Handling)
&emsp;&emsp; 协程中未处理的异常会向上冒泡，传给 `next()` 函数或 `send()` 方法的调用方（即触发协程的对象） 




https://zhuanlan.zhihu.com/p/30275154

https://www.zhihu.com/question/35139020


https://www.zhihu.com/question/50185085/answer/183463734