[toc]






&emsp;
&emsp; 
# 1. 背景
## 1.1 为什么要使用多进程？
&emsp;&emsp; 虽然线程更为轻量级，调度也更方便，但是python本身存在`GIL(Global Interpreter Lock)`，而且任何Python线程执行前，必须先获得`GIL`锁，然后，每执行一段时间后，解释器就自动释放GIL锁，让别的线程有机会执行。
&emsp;&emsp; 换句话说就是多线程的时候，同一时间只能有一个线程在CPU上运行，不管你的CPU有多少个核，同一时间都只能运行一个线程。
&emsp;&emsp; `GIL`的存在让python的多线程无法利用多核CPU的优势，所以想发挥多核CPU来实现并行，采用多进程是更好的方法。

## 1.2 Python的多进程模块有哪些？它们各自有什么特点？
Python多进程有内置模块 `multiprocessing` 和 `subprocess`：
`multiprocess`: 是同一个代码中通过多进程调用其他的模块（也是自己写的）
`subprocess` : 直接调用外部的二进制程序，而非代码模块






&emsp;
&emsp; 
# 2. `multiprocessing`模块 
## 2.1 如何利用`multiprocessing` 编写多进程程序？
&emsp;&emsp; 我们可以通过函数、类两种方法来编写多进程程序，这两种方法都要用到`multiprocessing.Process`。
### 方法一：函数式
① 编写需要被子进程运行的函数`func()`；
② 创建`multiprocessing.Process`类的实例，然后通过这个实例来运行你需要运行的函数`func()`。

```python
from multiprocessing import Process
import os

def func(name, i):
    print(f"我是老{i}，我叫 {name}，我的PID是{os.getpid():>6}，PPID是 {os.getppid()}")


if __name__ == "__main__":
    process_list = []
    for i, name in enumerate("Python", 1):
        p = Process(target=func, args=(name, i))
        p.start()
        process_list.append(p)
    for i in process_list:
        i.join()       
```
运行结果：
```
我是老1，我叫 P，我的PID是  7616，PPID是 4152
我是老2，我叫 y，我的PID是 20280，PPID是 4152
我是老3，我叫 t，我的PID是 11840，PPID是 4152
我是老4，我叫 h，我的PID是 13708，PPID是 4152
我是老6，我叫 n，我的PID是 11356，PPID是 4152
我是老5，我叫 o，我的PID是 11068，PPID是 4152
```

### 方法二：类继承式
① 首先，新建一个类`Myprocess`，这个类要继承`multiprocessing.Process`类；
② 覆盖父类的`run()`方法，需要将其实现为需要多进程运行的函数（因为`start()`默认调用`run()`方法）。
③ 实例化类`Myprocess`，然后调用它的`start()`方法，解释器将自动调用`Myprocess.run()`
```python
from multiprocessing import Process
import os

class Myprocess(Process):
    def __init__(self, n, i):
        super().__init__()
        self.name = n
        self.seq = i

    def run(self):
        print(f"我是老{self.seq}，我叫 {self.name}，我的PID是{self.pid:>6}，PPID是 {os.getppid()}")


if __name__ == "__main__":
    process_list = []
    for i, name in enumerate("Python", 1):
        p = Myprocess(name, i)
        p.start()
        process_list.append(p)
    for i in process_list:
        i.join()    
```
运行结果：
```
我是老1，我叫 P，我的PID是  3324，PPID是 19504
我是老2，我叫 y，我的PID是 10780，PPID是 19504
我是老4，我叫 h，我的PID是  1932，PPID是 19504
我是老3，我叫 t，我的PID是 11564，PPID是 19504
我是老5，我叫 o，我的PID是 10180，PPID是 19504
我是老6，我叫 n，我的PID是  5108，PPID是 19504
```


&emsp;
## 2.2 `multiprocessing.Process`
### 2.2.1 `multiprocessing.Process`的类型是？
&emsp;&emsp; 它是一个类。

### 2.2.2 `multiprocessing.Process`接收的参数是？
`multiprocessing.Process`的构造函数接收的参数为：
```python
Process(group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None)
```
**形参：**
> &emsp;&emsp; `group`: 它的值始终为None，此参数的存在只是为了和`threading.Thread`保持一致(`group` should always be None; it exists solely for compatibility with `threading.Thread`. )
> &emsp;&emsp; `target`: 表示调用对象，即子进程要执行的任务（ target is the callable object to be invoked by the `run()` method. It defaults to None, meaning nothing is called.）
> &emsp;&emsp; `name`: 子进程的名称(name is the process name)
> &emsp;&emsp; `args`: 调用对象的位置参数元组(args is the argument tuple for the target invocation. )
> &emsp;&emsp; `kwargs`: 调用对象的字典（kwargs is a dictionary of keyword arguments for the target invocation.）
> &emsp;&emsp; `daemon`：If provided, the keyword-only daemon argument sets the process daemon flag to True or False. If None (the default), this flag will be inherited from the creating process.（daemon参数是在python3.3加入的）
> 

### 2.2.3 `multiprocessing.Process` 有哪些方法？
#### (1) `run()`           
&emsp;&emsp; 进程启动时运行的方法，它会去调用`target`指定的函数。也可以在子类中重载此方法。`标准 run()` 方法调用传递给对象构造函数的可调用对象作为目标参数（如果有），分别从 args 和 kwargs 参数中获取顺序和关键字参数。

#### (2) `start()`         
&emsp;&emsp; 启动进程。这个方法每个进程对象最多只能调用一次。它会将对象的 run() 方法安排在一个单独的进程中调用。

#### (3) `join([timeout])`
&emsp;&emsp; 内部是通过`wait()`实现的。等待子进程退出，如果没有`join()`，则子进程会变成僵尸进程。
&emsp;&emsp; 如果可选参数 `timeout` 是 `None` （默认值），则该方法将阻塞，直到调用 join() 方法的进程终止。
&emsp;&emsp; 如果 timeout 是一个正数，它最多会阻塞 `timeout` 秒。请注意，如果进程终止或方法超时，则该方法返回 None 。通过检查进程的 `exitcode` 以确定它是否终止。
&emsp;&emsp; 一个进程可以被 join 多次。但进程无法`join`自身，因为这会导致死锁。尝试在启动进程之前`join`进程是错误的。

#### (4) `is_alive()`     
&emsp;&emsp; 判断当前进程是否活着。

#### (5) `terminate()`    
&emsp;&emsp; 通过给进程发送`SIGTERM`信号来终止进程。

#### (6) `kill()`         
&emsp;&emsp; 通过发送`SIGKILL`来终止进程。

#### (7) `close()`        
&emsp;&emsp; 这是python3.7加入的特性，用来关闭 `Process`对象，并释放与之关联的所有资源。如果底层进程仍在运行，则会引发 `ValueError` 。一旦 `close()` 成功返回，调用`Process`对象的大多数其他方法和属性将引发 `ValueError` 。

### 2.2.4 `multiprocessing.Process`中的`kill()`和`terminate()`
#### (1) 它们方法有什么区别？
它俩都是用来终止进程的。它们之间的差异在于给进程发送的信号：
> `terminate()`发送`SIGTERM`信号；
> `kill()` 发送`SIGKILL`；
> 
所以它俩的区别可以理解为`SIGTERM`和`SIGKILL`的区别：
> `SIGTERM`和`SIGKILL`都是用来终止进程的，但是它们之间的区别的主要是能不能被信号处理函数阻塞：
> &emsp;&emsp; `SIGTERM`是可以被信号处理器阻塞的，如果进程定义了自己的信号处理函数，那么完全可以不杀死自己；
> &emsp;&emsp; `SIGKILL`是必杀信号，信号处理器也不能将其阻塞。
> 
#### (2) 平常用哪个比较好？
&emsp;&emsp; 正常情况下建议使用`terminate()`，因为它会调用信号处理程序，而且在信号处理程序中可能有一些资源的清理工作，这样可以避免资源泄露的风险。
&emsp;&emsp; 如果实在杀不掉，再调用`kill()`

### 2.2.5 `multiprocessing.Process` 有哪些属性？？
#### (1) `name`
&emsp;&emsp; 进程的名称。该名称是一个字符串，仅用于识别目的。它没有语义。我们可以为多个进程指定相同的名称。
&emsp;&emsp; 初始名称由构造器设定。 如果没有为构造器提供显式名称，则会构造一个形式为 `'Process-N1:N2:...:Nk'` 的名称，其中每个 `Nk` 是其父亲的第 `N` 个孩子。
#### (2) `daemon`
&emsp;&emsp; 进程的守护标志，一个布尔值。这必须在 start() 被调用之前设置。
&emsp;&emsp; 它的初始值继承自创建进程。
&emsp;&emsp; 当进程退出时，它会尝试终止其所有守护进程子进程。
&emsp;&emsp; 请注意，不允许在守护进程中创建子进程。这是因为当守护进程由于父进程退出而中断时，其子进程会变成孤儿进程。 另外，这些 不是 Unix 守护进程或服务，它们是正常进程，如果非守护进程已经退出，它们将被终止（并且不被合并）。
#### (3) `pid`
&emsp;&emsp; 返回进程ID。在生成该进程之前，这将是 None 。如果要返回父进程的进程ID，只能通过`os.ppid()`
#### (4) `exitcode`
&emsp; 子进程的退出代码：
&emsp;&emsp; 如果进程尚未终止，这将是 `None` 。
&emsp;&emsp; 若为负值 `-N` 表示子进程被信号 `N` 终止。
#### (5) `authkey`
&emsp;&emsp; 这是进程的身份验证密钥（字节字符串）。当 `multiprocessing` 初始化时，主进程使用 `os.urandom()` 分配一个随机字符串。
&emsp;&emsp; 当创建 Process 对象时，它将继承其父进程的身份验证密钥，尽管`authkey` 肯被设置为另一个字节字符串来更改。
#### (6) `sentinel`
&emsp;&emsp; 系统对象的数字句柄，当进程结束时将变为 "ready" 。如果要使用 `multiprocessing.connection.wait()` 一次等待多个事件，可以使用此值。否则调用 `join()` 更简单。

### 在`Process`中如何获取PID和PPID？
&emsp;&emsp; `PID`可以直接通过类属性`Process.pid`；
&emsp;&emsp; `PPID`只能通过`os.ppid()`

&emsp;
## 2.3 `multiprocessing`模块中的 IPC
### 2.3.1 `multiprocessing`有哪些IPC方法？它们各自的应用场景是？
&emsp;&emsp; `multiprocessing`模块支持两种IPC方式： 队列(Queue)和管道(Pipe)。
> 队列(Queue) ：能够在多个生产者和消费者之间通信
> 管道(Pipe) : 能够在两个进程间互相传递消息
> 

### 2.3.2 `Pipe()` 
#### (1) `Pipe`是什么类型？
&emsp;&emsp; `Pipe`是一个**函数**。
#### (2) `Pipe()`的形参、返回值分别是什么？
`Pipe()`的函数原型如下：
```python
conn1, conn2 = Pipe(duplex=True)
```
形参：
> ① **返回值`conn1, conn2`**：两个都是`Connection`对象
> ② **形参`duplex`**：指定返回的连接对象是否是双工的：
> &emsp;&emsp; 默认是`True`(双工)，即 conn1和conn2都是可读可写；
> &emsp;&emsp; 若为`False`则为 非双工，即 conn1 只能用于接收消息，而 conn2 仅能用于发送消息。
> 
**`duplex`参数可以指定返回的`Connection`对象是否可读可写：**
```python
from multiprocessing import Process, Pipe
import os
from time import sleep

def func(read):
    recv_msg = read.recv() # 从管道中读取消息
    print(recv_msg)

if __name__ == "__main__":
    read, write = Pipe(duplex=False)     
    p = Process(target=func, args=(read, ) )
    p.start()
    write.send(f"Hello, son, I am your father {os.getpid()}.\n")
    sleep(1)
    read.send(f"Writing by {read}.")
    print(read.recv())
    p.join()
```
运行结果：
```
Hello, son, I am your father 18796.

Traceback (most recent call last):
  File "d:\code_practice\practice.py", line 15, in <module>
    read.send(f"Writing by {read}.")
  File "C:\Users\Garin\AppData\Local\Programs\Python\Python310\lib\multiprocessing\connection.py", line 210, in send
    self._check_writable()
  File "C:\Users\Garin\AppData\Local\Programs\Python\Python310\lib\multiprocessing\connection.py", line 149, in _check_writable        
    raise OSError("connection is read-only")
OSError: connection is read-only
```
**结果分析：**
&emsp;&emsp; 可以看到的是，指定`duplex=False`后，对读端进行写操作将触发异常。

#### (3) `Pipe()`有哪些方法？
`Pipe()`不是类，它是一个函数，它没有方法，不过它返回的`Connection`对象是一个类，我们的`get()`和`put`其实操作的就是这个对象，这个对象有如下方法：
##### ① `send(obj)`
&emsp;&emsp; 将一个对象发送到连接的另一端，可以用 `recv()` 读取。
&emsp;&emsp; 发送的对象必须是可以序列化的，过大的对象 ( 接近 32MiB+ ，这个值取决于操作系统 ) 有可能引发 `ValueError` 异常。
##### ② `recv()`
&emsp;&emsp; 返回一个由另一端使用 `send()` 发送的对象。该方法会一直阻塞直到接收到对象。 如果对端关闭了连接或者没有东西可接收，将抛出 `EOFError` 异常。
##### ③ `fileno()`
&emsp;&emsp; 返回由连接对象使用的描述符或者句柄。
##### ④ `close()`
&emsp;&emsp; 关闭连接对象。
&emsp;&emsp; 当连接对象被垃圾回收时会自动调用。
##### ⑤ 其它方法
`Connection`对象还有如下几个方法：
>`send_bytes(buffer[, offset[, size]])`
>`recv_bytes([maxlength])`
>`recv_bytes_into(buffer[, offset])`
>
本文不作介绍，有需要再查文档。

#### (4) 使用`Pipe`有什么风险？
&emsp;&emsp; `Pipe()`会返回的两个连接对象用于表示管道的两端。每个连接对象都有 `send()` 和 `recv()` 方法（相互之间的）。
&emsp;&emsp; 但需要注意的是，如果两个进程（或线程）**同时尝试** 读取或写入管道的同一 端，则管道中的数据可能会损坏。当然，在不同进程中同时使用管道的不同端的情况下不存在损坏的风险。
&emsp;&emsp; 换句话说，就是 在同一时刻对同一个管道进行性 进行 读(写) 是有风险的。
#### (5) 如何正确的使用`pipe()`，从而避免斯上面提到的风险?
&emsp;&emsp; 其实和`TLPI`中关于使用`pipe()`系统调用的方法一样：
> ① 新建两个管道`A`和`B`；
> ② 父进程关闭`A`的读端，`B`的写端；
> ③ 子进程关闭`A`的写端，`B`的读端
> 
这样就能无风险的使用`Pipe()`了。但其实在Python中，上述操作没那么复杂，利用`duplex`参数可以简化操作：
```python
from multiprocessing import Process, Pipe
import os

def func(read, write):
    recv_msg = read.recv()
    print(f"PID: {os.getpid():>6}, received message: {recv_msg}")
    write.send(f"Hello, dad, I am {os.getpid()}.")


if __name__ == "__main__":
    parent_read, son_write = Pipe(duplex=False)
    son_read, parent_write = Pipe(duplex=False)        
    p = Process(target=func, args=(son_read,son_write) )
    p.start()
    parent_write.send(f"I'm your father.")
    recv_msg = parent_read.recv()
    print(f"pid: {os.getpid():>6}, received message: {recv_msg}")
    p.join()
```
运行结果：
```
PID:  11756, received message: I'm your father.
pid:  16236, received message: Hello, dad, I am 11756.
```

### 2.3.3 `Queue`
#### (1) `Queue`是什么类型？
&emsp;&emsp; `Queue`是一个类。
#### (2)`Queue`的构造函数是怎样的？
在构建`Queue`实例时，它会接收一个可选参数`maxsize`
```python
class multiprocessing.Queue([maxsize])
```
#### (3)  `Queue`有哪些方法？
##### ① `put(obj[, block[, timeout]])`
&emsp; 作用是将 `obj` 放入队列：
> &emsp;&emsp; 如果 可选参数`block` 是 `True`(默认值) 而且 `timeout` 是 `None`(默认值), 将会阻塞当前进程，直到有空的缓冲槽。如果 `timeout` 是正数，将会在阻塞了最多 `timeout` 秒之后还是没有可用的缓冲槽时抛出 queue.Full  异常。
> &emsp;&emsp; 反之 (`block` 是 `False` 时)，仅当有可用缓冲槽时才放入对象，否则抛出 `queue.Full` 异常 (在这种情形下 `timeout` 参数会被忽略)。
> 
##### ② `get([block[, timeout]])`
&emsp; 从队列中取出并返回对象，**注意，get()会从队列中删除取出来的对象！**(Remove and return an item from the queue.)
> &emsp;&emsp; 如果可选参数 `block` 是 `True`(默认值) 而且 `timeout` 是 `None` (默认值), 将会阻塞当前进程，直到队列中出现可用的对象。如果 `timeout` 是正数，将会在阻塞了最多 `timeout` 秒之后还是没有可用的对象时抛出 `queue.Empty` 异常。
> &emsp;&emsp; 反之 (`block` 是 `False` 时)，仅当有可用对象能够取出时返回，否则抛出 `queue.Empty` 异常 (在这种情形下 `timeout` 参数会被忽略)。
> 
##### ③ `qsize()`
&emsp;&emsp; 返回队列的大致长度。由于多线程或者多进程的上下文，这个数字是不可靠的。
##### ④ `empty()`
&emsp;&emsp; 如果队列是空的，返回 True ，反之返回 False 。 由于多线程或多进程的环境，该状态是不可靠的。
##### ⑤ `full()`
&emsp;&emsp; 如果队列是满的，返回 True ，反之返回 False 。 由于多线程或多进程的环境，该状态是不可靠的。

#### (4) 如何使用`Queue`？
生产者调用`put()`方法写入信息，消费者调用`get()`方法获取信息：
```python
from multiprocessing import Process, Queue
import os

def func(q):
    q.put(f"Hello, dad, I am your son {os.getpid():>6}.")


if __name__ == "__main__":
    q = Queue()       
    p = Process(target=func, args=(q, ) )
    p.start()
    recv_msg = q.get()
    print(f"Reveived: {recv_msg}")
    p.join()
```
运行结果：
```
Reveived: Hello, dad, I am your son  18344.
```

#### (5) 使用`Queue`应该注意什么？
&emsp;&emsp; `如果一个进程在尝试使用 `Queue` 期间被 `Process.terminate()` 或 `os.kill()` 调用终止了，那么队列中的数据很可能被破坏。这可能导致其他进程在尝试使用该队列时发生异常。

#### (6)  `multiprocessing.Queue` 是怎么实现的 ？
&emsp;&emsp; 它是一个管道 、 少量锁 和 信号量 实现的共享队列。

### 2.3.4 `Queue`和`Pipe()`如何选择？
&emsp;&emsp; `Queue`用于 生产者消费者 模式中，并且支持多个生产者和消费者：生产者调用`put()`方法，消费者调用`get()`方法；
&emsp;&emsp; `Pipe()`用于 进程间通信，通常管道的两端需要互发消息。

### 2.3.5 `multiprocessing.SimpleQueue`
#### (1) 介绍
`multiprocessing.SimpleQueue`在python3.9加入，是一个简化版的`multiprocessing.Queue`类型，包含如下几个方法：
> ① `close()` : Close the queue: release internal resources.
> &emsp;&emsp; A queue must not be used anymore after it is closed. For example, get(), put() and empty() methods must no longer be called.
> ② `empty()` : Return True if the queue is empty, False otherwise.
> ③ `get()` : Remove and return an item from the queue.
> ④ `put(item)` : Put item into the queue.
> 
#### (2) 使用实例
以下来自《Fluent Python》第二版第19章：
```python
import sys
import math
from time import perf_counter
from typing import NamedTuple
from multiprocessing import Process, SimpleQueue, cpu_count
from multiprocessing import queues

PRIME_FIXTURE = [
    (2, True),
    (142702110479723, True),
    (299593572317531, True),
    (3333333333333301, True),
    (3333333333333333, False),
    (3333335652092209, False),
    (4444444444444423, True),
    (4444444444444444, False),
    (4444444488888889, False),
    (5555553133149889, False),
    (5555555555555503, True),
    (5555555555555555, False),
    (6666666666666666, False),
    (6666666666666719, True),
    (6666667141414921, False),
    (7777777536340681, False),
    (7777777777777753, True),
    (7777777777777777, False),
    (9999999999999917, True),
    (9999999999999999, False),
]

NUMBERS = [n for n, _ in PRIME_FIXTURE]

# tag::IS_PRIME[]
# 用于计算是否 素数(prime)
def is_prime(n: int) -> bool:
    if n < 2:
        return False
    if n == 2:
        return True
    if n % 2 == 0:
        return False

    root = math.isqrt(n)
    for i in range(3, root + 1, 2):
        if n % i == 0:
            return False
    return True
# end::IS_PRIME[]


# 用来存储返回结果
class PrimeResult(NamedTuple):
    n: int # 数字，如 3333333333333333，用于标识结果
    prime: bool # 结果
    elapsed: float # 耗时


# JobQueue 和 ResultQueue都是类型别名，用于后面的类型注解
JobQueue = queues.SimpleQueue[int]
ResultQueue = queues.SimpleQueue[PrimeResult]


def check(n: int) -> PrimeResult:
    t0 = perf_counter()
    res = is_prime(n)
    return PrimeResult(n, res, perf_counter() - t0)


# 工作函数
def worker(jobs: JobQueue, results: ResultQueue) -> None:
    while n := jobs.get():    # 获取一个任务
        results.put(check(n)) # 调用check()计算 数字n 是否素数，然后把结果加入到 结果队列results
    results.put(PrimeResult(0, False, 0.0)) # 用于告诉 主进程 工作进程们都完成工作了。


# 开启任务
def start_jobs(procs: int, jobs: JobQueue, results: ResultQueue) -> None:
    for n in NUMBERS:
        jobs.put(n)
    for _ in range(procs): # 进程数 = CPU核数
        proc = Process(target=worker, args=(jobs, results))
        proc.start()
        jobs.put(0) # 0 是哨兵值，用于告诉进程该终止了


def main() -> None:
    # 如果没有在命令行指定进程数量，那进程数就取CPU内核数
    if len(sys.argv) < 2:
        procs = cpu_count()
    else:
        procs = int(sys.argv[1])
    print(f'Checking {len(NUMBERS)} numbers with {procs} processes:')
    t0 = perf_counter()
    jobs: JobQueue = SimpleQueue()
    results: ResultQueue = SimpleQueue()
    start_jobs(procs, jobs, results)
    checked = report(procs, results)
    elapsed = perf_counter() - t0
    print(f'{checked} checks in {elapsed:.2f}s')


def report(procs: int, results: ResultQueue) -> int:
    checked = 0
    procs_done = 0
    while procs_done < procs:
        n, prime, elapsed = results.get()
        if n == 0: # 如遇到了0，说明所有结果都出来了
            procs_done += 1
        else:
            checked += 1
            label = 'P' if prime else ' '
            print(f'{n:16} {label} {elapsed:9.6f}s')
    return checked


if __name__ == '__main__':
    main()
```
运行结果：
```
Checking 20 numbers with 12 processes:
               2 P  0.000001s
3333333333333333    0.000004s
4444444444444444    0.000001s
5555555555555555    0.000004s
6666666666666666    0.000001s
 142702110479723 P  0.981169s
7777777777777777    0.000005s
 299593572317531 P  1.416819s
9999999999999999    0.000005s
3333333333333301 P  4.415110s
3333335652092209    4.575092s
4444444444444423 P  5.021871s
4444444488888889    5.128732s
5555555555555503 P  5.441788s
5555553133149889    5.541085s
6666666666666719 P  5.808244s
6666667141414921    5.837217s
7777777536340681    6.152384s
7777777777777753 P  6.138048s
9999999999999917 P  5.978023s
20 checks in 7.07s
```


&emsp;
## 2.4 `multiprocessing`的进程池
### 2.4.1 为什么要使用进程池？
&emsp;&emsp; 虽然使用多进程能提高效率，但是进程的创建会消耗大量的计算机资源，使用进程池可以极大程度的避免创建进程带来的开销。

### 2.4.2 如何通过`multiprocessing`创建进程池？
&emsp;&emsp; 通过`multiprocessing.Pool`类 我们可以创建进程池：
```python
from multiprocessing import Pool

my_pool = Pool(processes = 5) # 创建一个包含5个进程的进程池
```

### 2.4.3 `multiprocessing.Pool`提供了哪些方法？
#### (1) `apply(func[, args[, kwds]])`
**参数：**
> &emsp;&emsp; **func**：需要运行的函数；
> &emsp;&emsp; **args**：位置参数；
> &emsp;&emsp; **kwds**：命名参数；
> 
**作用：**
&emsp;&emsp; 使用 args 参数以及 kwds 命名参数调用 func , 它会返回结果前阻塞。这种情况下，apply_async() 更适合并行化工作。另外 func 只会在一个进程池中的一个工作进程中执行。

#### (2)`apply_async(func[, args[, kwds[, callback[, error_callback]]]])`
**① 形参说明：**
> &emsp;&emsp; **func**：需要运行的函数；
> &emsp;&emsp; **args**：位置参数；
> &emsp;&emsp; **kwds**：命名参数；
> &emsp;&emsp; **callback**：当目标函数`func()`执行成功时，`callback`会被用于处理执行后的返回结果，否则，调用 `error_callback`。注意，`callback`必须是一个接受单个参数的可调用对象。
> &emsp;&emsp; **error_callback**：当目标函数`func()`执行失败时，会将抛出的异常对象作为参数传递给`error_callback`。注意，`error_callback`必须是一个接受单个参数的可调用对象。
> 
**② 函数的作用：**
&emsp;&emsp; 可以看作是**非阻塞**的`apply()`方法，将返回一个`AsyncResult`对象
**③ callback和error_callback指定的函数分别在什么时候被执行？**
&emsp;&emsp;当目标函数`func()`执行成功时，`callback`会被用于处理执行后的返回结果，否则，调用 `error_callback`。来看一个代码实例：
```python
from multiprocessing import Pool
from time import sleep
import os

def func(num):
    if num % 2 :
        raise RuntimeError(f"我是老{num}，进程ID是 {os.getpid()}")
    return "程序正常执行完毕。"

def callback(arg):
    print(f"callback()       received: {arg}")

def error_callback(arg):
    print(f"error_callback() received: {arg}")


if __name__ == "__main__":
    size = 5
    my_pool = Pool(processes = size) # 创建一个包含5个进程的进程池
    for i, _ in enumerate(range(size), 1):
        print(f"准备开始执行第 {i} 个子进程...")
        my_pool.apply_async(func, args=(i,), callback=callback, error_callback=error_callback)
    my_pool.close()
    my_pool.join()
```
运行结果：
```
准备开始执行第 1 个子进程...
准备开始执行第 2 个子进程...
准备开始执行第 3 个子进程...
准备开始执行第 4 个子进程...
准备开始执行第 5 个子进程...
error_callback() received: 我是老1，进程ID是 13800
callback()       received: 程序正常执行完毕。
error_callback() received: 我是老3，进程ID是 13800
callback()       received: 程序正常执行完毕。
error_callback() received: 我是老5，进程ID是 13800
```
**结果分析：**
&emsp;&emsp; 可以看到的是，发生异常时调用的是`error_callback`指定的函数，正常退出调用的是`callback`指定的函数。

#### (3) `map(func, iterable[, chunksize])`
&emsp;&emsp; 内置`map()`函数的并行版本。

#### (4) `map_async(func, iterable[, chunksize[, callback[, error_callback]]])`
&emsp;&emsp; `map()` 方法的一个变种，返回一个 `AsyncResult` 对象。
&emsp;&emsp; 如果指定了 `callback` , 它必须是一个接受单个参数的可调用对象。当执行成功时， `callback` 会被用于处理执行后的返回结果，否则，调用 `error_callback` 。
&emsp;&emsp; 如果指定了 `error_callback` , 它必须是一个接受单个参数的可调用对象。当目标函数执行失败时， 会将抛出的异常对象作为参数传递给 `error_callback` 执行。
&emsp;&emsp; 回调函数应该立即执行完成，否则会阻塞负责处理结果的线程。

#### (5) `close()`
&emsp;&emsp; 阻止后续任务提交到进程池，当所有任务执行完成后，工作进程会退出。

#### (6) `terminate()`
&emsp;&emsp; 不必等待未完成的任务，立即停止工作进程。当进程池对象被垃圾回收时，会立即调用 `terminate()`。

#### (7) `join()`
&emsp;&emsp; 等待工作进程结束。调用`join()`前 必须先调用`close()` 或 `terminate()`。

### 2.4.4 `Pool.apply()`和`Pool.apply_async()`有何区别？建议使用哪个？
#### (1) 区别
它俩主要区别是 是否阻塞的执行子进程：
> &emsp;&emsp; **`apply()`** 是阻塞的，意思就是等待当前子进程执行完毕后，在执行下一个进程。
> &emsp;&emsp; **`apply_async()`** 是非阻塞的，`async`后缀的意思是 异步的，主进程不用等待当前子进程执行完毕就会返回。
> 
```python
from multiprocessing import Pool
from time import sleep
import os

def func(num):    
    sleep(3)
    print(f"我是老{num}，进程ID是 {os.getpid()}")


if __name__ == "__main__":
    size = 5
    my_pool = Pool(processes = size) # 创建一个包含5个进程的进程池
    for i, _ in enumerate(range(size), 1):
        my_pool.apply_async(func, args=(i,))
        print(f"第 {i} 个子进程已开始执行\n")
    my_pool.close()
    my_pool.join()
    print("Done.")
```
运行结果：
```
第 1 个子进程已开始执行

第 2 个子进程已开始执行

第 3 个子进程已开始执行

第 4 个子进程已开始执行

第 5 个子进程已开始执行

我是老2，进程ID是 2004
我是老4，进程ID是 3124
我是老3，进程ID是 8412
我是老1，进程ID是 17396
我是老5，进程ID是 12248
Done.
```
把`apply_async()`改成`apply()`，输出为：
```
我是老1，进程ID是 13000
第 1 个子进程已开始执行

我是老2，进程ID是 8908
第 2 个子进程已开始执行

我是老3，进程ID是 6332
第 3 个子进程已开始执行

我是老4，进程ID是 10556
第 4 个子进程已开始执行

我是老5，进程ID是 8288
第 5 个子进程已开始执行

Done.
```
**结果分析：**
&emsp;&emsp; 可以看到的是，`apply()`的输出结果明显是串行执行，只有在`func()`执行完毕才会执行下一个进程；
&emsp;&emsp; 而`apply_async()`不会等`func()`执行完毕，他会立即返回。

#### (2) 建议使用哪个？
&emsp;&emsp; 官方建议使用`apply_async()`，这样才能发挥多进程的优势。（`apply()`这个方法很鸡肋）

### 2.4.5 `Pool.map()`和`Pool.map_async()`
#### (1) `Pool.map()`和`Pool.map_async()`有何区别？建议使用哪个？
&emsp;&emsp; 它们除了形参不一样之外，主要区别在于是否阻塞主进程：
> `Pool.map()` 会阻塞主进程，它会等待所有任务完成才返回；
> `Pool.map_async()` 不会阻塞主进程，它在将任务交给进程池后会立即返回。
> 
具体使用哪个看需求，如果希望主进程阻塞，那就用`map()`，否则就用`map_async()`。

#### (2) `Pool.map()`和`Pool.map_async()`在执行子进程时是并行还是串行？
&emsp;&emsp; 它们俩都是并行的，这从上面的例子的输出结果就能看出来。串行执行的只有`Pool.apply()`。

#### (3) 实例验证
```python
from multiprocessing import Pool
import os

def func(num):    
    print(f"我是老{num}，进程ID是 {os.getpid()}")


if __name__ == "__main__":
    size = 10
    my_pool = Pool(processes = size) # 创建一个包含5个进程的进程池

    my_pool.map(func, [i for i in range(1, size)]) 
    
    print("map()")  

    my_pool.map_async(func, range(1, size))
    print("map_async()")
    my_pool.close()
    my_pool.join()
    print("Done.")
```
运行结果：
```
我是老1，进程ID是 13264
我是老3，进程ID是 13264
我是老4，进程ID是 13264
我是老5，进程ID是 13264
我是老6，进程ID是 10344
我是老8，进程ID是 10344
我是老9，进程ID是 10344
我是老7，进程ID是 13264
我是老2，进程ID是 5628
map()
map_async()
我是老2，进程ID是 13264
我是老3，进程ID是 16492
我是老1，进程ID是 10344
我是老4，进程ID是 9028
我是老9，进程ID是 9028
我是老6，进程ID是 13264
我是老7，进程ID是 10344
我是老8，进程ID是 16492
我是老5，进程ID是 5628
Done.
```
**结果分析：**
&emsp; 从输出结果可以看到：
> &emsp;&emsp; ① `Pool.map()` 会阻塞主进程，它会等待所有任务完成才返回；而`Pool.map_async()` 不会阻塞主进程，它在将任务交给进程池后会立即返回。
> &emsp;&emsp; ② 它俩在执行子进程的时候都是并行的，因为它们调用`func()`的输出都是无序的。
> 

### 2.4.6 进程池中执行并行任务有哪几种方法？这些方法有何不一样？
有如下四种方法：
> ① `map`	
> ② `apply`
> ③ `map_async`
> ④ `apply_async`
> ⑤ 其它`map`的变体
> 
对于`map_async`和`apply_async`的区别，来看一个例子：
```python
my_pool.map_async(func, range(1, 11))
```
相当于：
```python
for i in range(1, 11):
    my_pool.apply_async(func, (i, ))
```

### 2.4.7 使用`multiprocessing.Pool`的注意事项
&emsp; 使用`multiprocessing.Pool`时需要注意：
> &emsp;&emsp; ① 使用`apply_async()`来执行进程；
> &emsp;&emsp; ② 调用`join()`前 别忘了先调用`close()` 或 `terminate()`
> 

### 2.4.8 进程池对象和上下文管理器协议
`multiprocessing.Pool`类实现了`__enter__()` 和 `__exit__()`方法，所以它支持 上下文管理协议。
```python
from multiprocessing import Pool, TimeoutError

def func(x):
    return x*x

if __name__ == '__main__':
    # start 4 worker processes
    with Pool(processes=4) as pool:
        print(pool.map(func, range(10)))
```
运行结果：
```
[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
```

&emsp;
## 2.5 `multiprocessing`模块中的 进程间同步
&emsp;&emsp; `multiprocessing`提供的同步方法有：Lock(非递归锁)、RLock(递归锁)、Semaphore(信号量)、Event(事件)和Condition(条件变量)。
### 2.5.1 `Lock`
&emsp;&emsp; 原始锁（非递归锁）对象，类似于 threading.Lock 。一旦一个进程或者线程拿到了锁，后续的任何其他进程或线程的其他请求都会被阻塞直到锁被释放。

### 2.5.2 `RLock`
&emsp;&emsp; 递归锁对象。递归锁必须由持有线程、进程亲自释放。如果某个进程或者线程拿到了递归锁，这个进程或者线程可以再次拿到这个锁而不需要等待。但是这个进程或者线程的拿锁操作和释放锁操作的次数必须相同。

### 2.5.3 `Semaphore`
&emsp;&emsp; 信号量对象。

### 2.5.4 `Event`
&emsp;&emsp; 

### 2.5.5 `Condition([lock])`
&emsp;&emsp; 条件变量，指定的 `lock`参数 应该是 `multiprocessing` 模块中的 `Lock` 或 `RLock` 对象。



&emsp;
## 2.6 `multiprocessing`模块中的 进程间共享状态
### 2.6.1 进程间通信 和 进程间共享状态
&emsp;&emsp; `Pipe`和`Queue`实现了进程间通信，但是没有提供进程间共享状态的功能。虽然在进行并发编程时，通常最好尽量避免使用共享状态。使用多个进程时尤其如此。但是，如果你真的需要使用一些共享数据，那么 multiprocessing 提供了两种方法。

### 2.6.2 共享内存
&emsp;&emsp; 可以使用 `Value` 或 `Array` 将数据存储在共享内存映射中。
```python
from multiprocessing import Process, Value, Array

def f(n, a):
    n.value = 3.1415927
    for i in range(len(a)):
        a[i] = -a[i]

if __name__ == '__main__':
    num = Value('d', 0.0)
    arr = Array('i', range(10))

    p = Process(target=f, args=(num, arr))
    p.start()
    p.join()

    print(num.value)
    print(arr[:])
```
运行结果：
```
3.1415927
[0, -1, -2, -3, -4, -5, -6, -7, -8, -9]
```
**结果分析：**
&emsp;&emsp; 可以看到的是，子进程修改了`num`和`arr`后，父进程对应的对象也被修改了。

### 2.6.3 服务进程
&emsp;&emsp; 由 `Manager()` 返回的管理器对象控制一个服务进程，该进程保存Python对象并允许其他进程使用代理操作它们。
&emsp;&emsp; `Manager()` 返回的管理器支持类型： `list` 、 `dict` 、 `Namespace` 、 `Lock` 、 `RLock` 、 `Semaphore` 、 `BoundedSemaphore` 、 `Condition` 、 `Event` 、 `Barrier` 、 `Queue` 、 `Value` 和 `Array` 。例如：
```python
from multiprocessing import Process, Manager

def f(d, l):
    d[1] = '1'
    d['2'] = 2
    d[0.25] = None
    l.reverse()

if __name__ == '__main__':
    with Manager() as manager:
        d = manager.dict()
        l = manager.list(range(10))

        p = Process(target=f, args=(d, l))
        p.start()
        p.join()

        print(d)
        print(l)
```
运行结果：
```
{1: '1', '2': 2, 0.25: None}
[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
```

### 2.6.4 使用哪个？
&emsp;&emsp; 使用服务进程的管理器比使用共享内存对象更灵活，因为它们可以支持任意对象类型。此外，单个管理器可以通过网络由不同计算机上的进程共享。但是，它们比使用共享内存慢。
&emsp;&emsp; 因此，用哪个就看需求了。






&emsp;
&emsp; 
# 3. `subprocess`
## 3.1 `subprocess`出现的原因
&emsp;&emsp; `subprocess`subprocess 模块允许你生成新的进程，连接它们的输入、输出、错误管道，并且获取它们的返回码。此模块打算代替一些老旧的模块与功能：
> ① `os.system`
> ② `os.spawn*`
> 
因为这些老的模块略显混乱使开发者难以抉择，标准库的开发者想打造一个“统一”模块来提供之前进程创建相关函数的功能实现，于是`subprocess`模块出现了。

## 3.2 `subprocess`和`multiprocessing`有何不同？
&emsp;&emsp; `subprocess`主要用于调直接调用外部的二进制程序，而非代码模块。

## 3.3 如何使用`subprocess`模块
&emsp; 有两种方法：
> &emsp;&emsp; ① `subprocess.run()`函数
> &emsp;&emsp; ② `subprocess.Popen`类
> 

## 3.4 `subprocess.run()`函数
### 3.4.1 函数原型 和 形参解释
```python
subprocess.run(args, *, stdin=None, input=None, stdout=None, stderr=None, 
        capture_output=False, shell=False, cwd=None, timeout=None, 
          check=False, encoding=None, errors=None, text=None, 
            env=None, universal_newlines=None, **other_popen_kwargs)
```
函数作用：运行被 `arg`参数 描述的指令，主进程**阻塞的等待**指令完成, 然后返回一个 `CompletedProcess` 实例.
#### ① `args` ：
&emsp;&emsp; 表示要执行的命令，必须是一个字符串 或 字符串参数列表。
#### ② `stdin、stdout、stderr` ：
&emsp;&emsp; 子进程的标准输入、输出和错误。其值可以是`subprocess.PIPE`(为子进程创建新的管)、`subprocess.DEVNULL`(使用`os.devnull`)、一个已经存在的文件描述符、已经打开的文件对象或者 `None`。
#### ③ `capture_output`(python3.7添加)
&emsp;&emsp; 如果`capture_output=True`，`stdout` 和 `stderr` 都将被捕获并使用`subprocess.PIPE`创建，即相当于`stdout =subprocess.PIPE, stderr=subprocess.PIPE`，换句话说：
```python
subprocess.run(["ls", "-al"], capture_output=True)
```
其实等价于：
```python
subprocess.run(["ls", "-al"], stdout =subprocess.PIPE, stderr=subprocess.PIPE)
```
另外，`stdout` 和 `stderr` 参数**不应当**与 `capture_output` 同时被提供。

#### ④ `shell`
&emsp;&emsp; 如果该参数为`True`，将通过操作系统的shell(Linux为bash，windows为powershell) 执行指定的命令。
#### ⑤ `check`
&emsp;&emsp; 如果该参数设置为`True`，且进程退出状态码不是 `0`，则弹出`CalledProcessError`异常。
#### ⑥ `timeout`
&emsp;&emsp; 设置命令超时时间。如果命令执行时间超时，子进程将被杀死，并弹出`TimeoutExpired`异常。
#### ⑦ `input`
&emsp;&emsp; 该参数将被传递给`Popen.communicate()`，然后传递给子进程的标准输入`stdin`。该参数数据类型应为字节序列（bytes）;
#### ⑧ `env`
&emsp;&emsp; 如果 `env` 不是 `None`, 它必须是一个字典, 用于为新的进程设置环境变量; 它用于替换继承的当前进程的环境的默认行为. 它将直接被传递给 `Popen`。

### 3.4.2 `subprocess.run()`函数是否阻塞？
&emsp;&emsp; 是阻塞的，调用`subprocess.run()`函数的 主进程会 **阻塞的等待**指令完成。

### 3.4.3 如何将`stdout`和`stderr`写入到一个流中？
使用 `stdout=PIPE` 和 `stderr=STDOUT `来代替 `capture_output`，例如：
```python
import subprocess

if __name__ == "__main__":
    print(subprocess.run(["ls", "-al"], stdout=subprocess.PIPE, stderr=subprocess.STDOUT))
```

### 3.4.4 如何执行带参数的`shell`命令？
有两种方法：
> ① 将`args`参数设为列表，并将命令和对应的参数分别作为列表的一个元素。
> ② 指定`shell`参数，直接执行带参数的命令；
> 
```python
import subprocess

if __name__ == "__main__":
  # ① 将`args`参数设为列表，并将命令和对应的参数分别作为列表的一个元素。
    print(subprocess.run(["ls", "-al"],stdout =subprocess.PIPE))
    
    print("\n")

  # 使用`shell`参数
    print(subprocess.run("ls -al", shell=True,stdout =subprocess.PIPE))
```
运行结果：
```
CompletedProcess(args=['ls', '-al'], returncode=0, stdout=b'total 4\ndrwxrwxr-x. 2 alpha alpha  21 Dec  6 21:07 .\ndrwxrwxr-x. 4 alpha alpha  38 Oct 22 21:28 ..\n-rw-rw-r--. 1 alpha alpha 206 Dec  6 21:07 test.py\n')


CompletedProcess(args='ls -al', returncode=0, stdout=b'total 4\ndrwxrwxr-x. 2 alpha alpha  21 Dec  6 21:07 .\ndrwxrwxr-x. 4 alpha alpha  38 Oct 22 21:28 ..\n-rw-rw-r--. 1 alpha alpha 206 Dec  6 21:07 test.py\n')
```

&emsp;
## 3.5 `subprocess.CompletedProcess`
### 3.5.1 `CompletedProcess`是什么？
&emsp;&emsp; 这是`subprocess.run()` 的返回值, 代表一个进程已经结束。

### 3.5.2 `CompletedProcess`有哪些属性和方法？
#### ① args
&emsp;&emsp; 被用作启动进程的参数。同`subprocess.run(args，***)` 中的`args`；

#### ② returncode
&emsp;&emsp; 子进程的退出状态码. 通常来说, 一个为 `0` 的退出码表示进程运行正常.

一个负值 -N 表示子进程被信号 N 中断 (仅 POSIX).

#### ③ stdout
&emsp;&emsp; 从子进程捕获到的标准输出. 一个字节序列, 或一个字符串, 如果 run() 是设置了 encoding, errors 或者 text=True 来运行的. 如果未有捕获, 则为 None.
如果你通过 stderr=subprocess.STDOUT 运行进程，标准输入和标准错误将被组合在这个属性中，并且 stderr 将为 None。

#### ④ stderr
&emsp;&emsp; 捕获到的子进程的标准错误. 一个字节序列, 或者一个字符串, 如果 run() 是设置了参数 encoding, errors 或者 text=True 运行的. 如果未有捕获, 则为 None.

#### ⑤ check_returncode()
&emsp;&emsp; 如果 `returncode` 非零, 抛出 `CalledProcessError`.

&emsp;
## 3.6 `subprocess`的旧接口
&emsp;&emsp; `run()`函数是在 Python3.5 新增，之前使用该模块的包括三个函数: `call()`, `check_call()`,` check_output()`。

&emsp;
## 3.7 `subprocess.Popen`类
### 3.7.1 `Popen` 的构造函数
```python
class subprocess.Popen(args, bufsize=-1, executable=None, stdin=None, stdout=None, stderr=None, preexec_fn=None, close_fds=True, shell=False, cwd=None, env=None, universal_newlines=None, startupinfo=None, creationflags=0, restore_signals=True, start_new_session=False, pass_fds=(), *, group=None, extra_groups=None, user=None, umask=- 1, encoding=None, errors=None, text=None, pipesize=- 1)
```

### 3.7.2 `Popen`的方法
#### ① `Popen.poll()`
&emsp;&emsp; 检查子进程是否已被终止，若结束则返回 `returncode` 属性。返回 None。

#### ② `Popen.wait(timeout=None)`
&emsp;&emsp; 阻塞父进程，等待子进程被终止，在子进程终止后会设置 `returncode`。
&emsp;&emsp; 如果进程在 `timeout`秒后未中断，会抛出一个`TimeoutExpired` 异常，此异常可被安全地捕获此并重新等待。
&emsp;&emsp; 需要注意的是，当 `stdout=PIPE` 或 `stderr=PIPE` 并且子进程产生的数据塞满了管道时，将会发生死锁。此类情况可通过`Popen.communicate()`解决。

#### ③ `Popen.communicate(input=None, timeout=None)`
&emsp;&emsp; 此方法用于和子进程交互：不但可从子进程的 `stdout` 和 `stderr` 读取数据，还能往子进程的`stdin`发送数据。此方法的形参如下：
> `input`参数为发送给子进程的数据，若不需要发送数据则应该为`None`。
> `timeout`参数 为等待时间，如果`timeout`秒后子进程还未终止，则会触发一个`TimeoutExpired`异常，捕获此异常并重新等待将不会丢失任何输出。
> 
`communicate()`将返回一个`(stdout_data, stderr_data)` 元组。如果文件以文本模式打开则为字符串；否则字节。
&emsp;&emsp; 如果需要要向进程的 `stdin` 传输数据，需要在创建`Popen`对象时通过参数`stdin=PIPE`：
```python
proc = subprocess.Popen(stdin=PIPE, ... )
```
类似的，要从`communicate()`返回的元组获取数据，同样需要设置 `stdout=PIPE`或`stderr=PIPE`：
```python
proc = subprocess.Popen(stdout=PIPE, stderr=PIPE, ... )
```
&emsp;&emsp; 在`timeout`到时后，子进程事不会被杀死的，因此一个行为良好的应用程序应该杀死子进程并完成通讯：
```python
proc = subprocess.Popen(...)
try:
    outs, errs = proc.communicate(timeout=15)
except TimeoutExpired:
    proc.kill()
    outs, errs = proc.communicate()
```

#### ④ `Popen.send_signal(signal)`
&emsp;&emsp; 作用：将信号`signal`发送给子进程。如果进程已完成则不做任何操作。

#### ⑤ `Popen.terminate()`
&emsp;&emsp; 停止子进程。 在 `POSIX` 操作系统上，此方法会发送`SIGTERM`给子进程。在 `Windows` 上则会调用 `Win32 API` 函数 `TerminateProcess()` 来停止子进程。

#### ⑥ `Popen.kill()`
&emsp;&emsp; 杀死子进程。在`POSIX`操作系统上，此函数会发送 `SIGKILL` 给子进程。 在 `Windows` 上 `kill()` 则是 `terminate()` 的别名。

### 3.7.3 `Popen`的属性
#### ① `Popen.args`
&emsp;&emsp; 同传给`Popen`的`args`，即`subprocess.Popen(args,...`中的`args`。
#### ② `Popen.stdin`
&emsp;&emsp; 如果给`Popen`的`stdin`参数是`PIPE`，则此属性是一个可写的流（类似于`open()`函数的返回值）。
#### ③ `Popen.stdout`
&emsp;&emsp; 如果给`Popen`的`stdout`参数是`PIPE`，则此属性是一个可读的流（类似于`open()`函数的返回值），里面包含的内容是子进程的输出。
#### ④ `Popen.stderr`
&emsp;&emsp; 如果给`Popen`的`stderr`参数是`PIPE`，则此属性是一个可读的流（类似于`open()`函数的返回值），里面包含的内容是子进程的错误。
#### ⑤ `Popen.pid`
&emsp;&emsp; 返回子进程的PID。若创建`Popen`对象时`shell=True`，则返回的是派生的shell的PID。
#### ⑥ `Popen.returncode`
&emsp;&emsp; 子进程的返回值， `poll()`、`wait()`、`communicate()`会修改`Popen.returncode`的值。
&emsp;&emsp; 如果`Popen.returncode`为`None`，则说明该子进程还未终止。
&emsp;&emsp; 如果`Popen.returncode`为复数`-N`，则表示该子进程被 信号值为`N`的信号杀死。

### 3.7.4 `Popen`会阻塞主进程吗？
&emsp;&emsp; 和`subprocess.run()`不一样的是，`subprocess.Popen`不会阻塞主进程，不过`Popen`有两个方法会阻塞：
> ① `Popen.wait(timeout=None)` : 等待子进程终止
> ② `Popen.communicate(input=None, timeout=None)` : 和子进程交互，发送和读取数据。
> 

&emsp;
## 3.8 `subprocess`的其它属性
### 3.8.1 `subprocess.DEVNULL`
&emsp;&emsp; 可作为`stdin, stdout, stderr`参数的实参，在Posix上一般值为`/dev/null`。

### 3.8.2 `subprocess.PIPE`
&emsp;&emsp; 可作为`stdin, stdout, stderr`参数的实参，表示新建一个管道连接到`stdin, stdout, stderr`。

### 3.8.3 `subprocess.STDOUT`
&emsp;&emsp; 可作为`stderr`的实参，表示 标准错误和标准输出应该连接到同一个文件描述符上。

&emsp;
## 3.9 `subprocess.run()`和`subprocess.Popen`
&emsp;&emsp; `subprocess.run()`其实是通过`subprocess.Popen`实现的。




&emsp;
&emsp; 
# 4. 为什么`__name__ == '__main__'`是必须的？
https://docs.python.org/3/library/multiprocessing.html







# 参考文献
1. [一篇文章搞定Python多进程(全)](https://zhuanlan.zhihu.com/p/64702600)
2. [Python程序入口 __name__ == '__main__' 有重要功能（多线程）而非编程习惯](https://zhuanlan.zhihu.com/p/340965963)
3. [Python multiprocess模块(下)](https://www.cnblogs.com/haitaoli/p/9849031.html)
4. [详解multiprocessing多进程](https://blog.csdn.net/brucewong0516/article/details/85788202)
5. [Python多进程 - subprocess & multiproces](https://www.cnblogs.com/brt2/p/13232368.html)
6. [subprocess --- 子进程管理](https://docs.python.org/3/library/subprocess.html)
7. [每周一个 Python 模块 | subprocess](https://zhuanlan.zhihu.com/p/91342640)
8. [python subprocess-更优雅的创建子进程](https://zhuanlan.zhihu.com/p/348311219)